---
title: Shader入门
date: 2021-12-05 22:46:00
updated: 2021-12-05 22:46:00
id: ml-20211205-224600-g174
categories:
	- Unity
	- TA
tags: 
	- Unity
	- TA
	- Shader
---

本书GitHub地址(https://github.com/candycat1992/Unity_Shaders_Book/tree/master)

- [渲染流水线](#渲染流水线)
	- [什么是流水线](#什么是流水线)
	- [什么是渲染流水线](#什么是渲染流水线)
		- [应用阶段](#应用阶段)
		- [几何阶段](#几何阶段)
		- [光栅化阶段](#光栅化阶段)
	- [CPU和GPU之间的通信](#cpu和gpu之间的通信)
		- [吧数据加载到显存中](#吧数据加载到显存中)
		- [设置渲染状态](#设置渲染状态)
		- [调用Draw Call](#调用draw-call)
		- [概述](#概述)
	- [GPU流水线](#gpu流水线)
		- [顶点着色器](#顶点着色器)
		- [裁剪](#裁剪)
		- [屏幕映射(Screen Mapping)](#屏幕映射screen-mapping)
		- [三角形设置](#三角形设置)
		- [三角形遍历(Triangle Traversal)](#三角形遍历triangle-traversal)
		- [片元着色器](#片元着色器)
		- [逐片元操作](#逐片元操作)
	- [总结](#总结)
- [Unity Shader基础](#unity-shader基础)
	- [概述](#概述-1)
	- [UnityShader的基础:ShaderLab](#unityshader的基础shaderlab)
	- [UnityShader的结构](#unityshader的结构)
	- [UnityShader的形式](#unityshader的形式)
		- [表面着色器](#表面着色器)
		- [顶点, 片元着色器](#顶点-片元着色器)
		- [固定函数着色器](#固定函数着色器)
- [学习Shader所需的数学基础](#学习shader所需的数学基础)
	- [笛卡尔坐标系](#笛卡尔坐标系)
		- [左手坐标系和右手坐标系](#左手坐标系和右手坐标系)
		- [习题](#习题)
	- [点和矢量](#点和矢量)
		- [矢量和标量的乘除法](#矢量和标量的乘除法)
		- [矢量的加减](#矢量的加减)
		- [矢量的模](#矢量的模)
		- [矢量的点积](#矢量的点积)
		- [向量的叉积](#向量的叉积)
		- [矢量的差积](#矢量的差积)
- [完毕](#完毕)

<!--more-->

# 渲染流水线

渲染流水线的最终目的在于生成(渲染)一张二维纹理, 即我们在电脑屏幕上看到的所有效果, 他的输入是一个虚拟摄像机, 一些光源, 一些Shader以及纹理等.

## 什么是流水线

![2_1-真实生活中的流水线][2_1-真实生活中的流水线]

当一个产品需要四个步骤,每个步骤需要一小时, 并不是说生产一个产品就需要四小时, 通过**流水线**每个步骤同时进行,就可以一小时产生一个产品.  
可用发现,流水线系统的运行效率取决于其中最慢的工序.  
理想情况下,将一个非流水线系统分为n个流水线阶段, 且每个阶段耗时相同, 则整个系统会获得n倍的效率提升.

## 什么是渲染流水线

将上述流水线的概念普及到计算机的图形渲染种  
渲染流水线的工作任务在于,由一个三维场景出发, 生成一张二维图像, 计算机需要从一系列参数(顶点,纹理,等)信息出发, 把这些信息转换为人眼可以看到的图像, 这些工作由CPU和GPU共同完成

![流水线中的三个概念阶段][流水线中的三个概念阶段]

`<Render-Time Rendering, Third Edition>`书种将渲染分为3个阶段
* 应用阶段(Application Stage)
* 几何阶段(Geometry Stage)
* 光栅化阶段(Resterizer Stage)

> 注意,这仅仅是概念性的阶段,每个阶段通常也是一个流水线系统

### 应用阶段

由应用主导,通常由CPU负责实现, 开发者拥有这个阶段的控制权

开发者有三个任务

1. 主备好场景数据,如`摄像机位置`,`视锥体`,`场景中的模型`,`光源`等.
2. 为提高渲染效率,需要进行一些粗粒度剔除工作, 把那些不可见的物体剔除出去,不需要将他们提交给几何阶段
3. 设置每个模型的渲染状态, 这些渲染状态包括但不限于`材质(漫反射,高光反射)`,`纹理`,`使用的Shader`等.

这一阶段最重要的是要输出渲染所需的几何信息,即**渲染图元(rendering primitives)**  
通俗来讲,渲染图元可以是点,线,三角面等, 这些渲染图元会被传递给下个阶段---`几何阶段`

> 剔除一般含有`遮挡剔除`,`层级剔除`,`视锥体剔除`等, 这取决于开发者.  

> 粗粒度剔除, 这是为了区分`裁剪(clipping)`与`剔除(culling)`的区别,  
> 粒度不同是指,*剔除是在object层面的*，对object的各项属性做处理,并决定是否部将其传入几何阶段, *裁剪是在图元（三角形）层面的*,对构成object mesh的三角形再做裁剪

### 几何阶段

处理所有和我们要绘制的几何相关的事情, 例如,决定需要绘制的图元是什么,怎样绘制他们,在哪里绘制他们.这一阶段通常在GPU上进行.

几何阶段负责和每个渲染图元打交道, 进行逐顶点,逐多边形的操作.  
这一阶段还可以细分为更小的流水线阶段,后面会提到.  

这一阶段最重要的是吧**顶点坐标变换到屏幕空间**中, 再交给*光栅器*进行处理.  
通过对输入的渲染图元进行多部处理后, 这一阶段将会输出屏幕空间的二维顶点坐标, 每个顶点对应的深度值,着色等相关信息, 并传递给下个阶段.

### 光栅化阶段

接受上个阶段传递的数据来生成屏幕上的像素, 并渲染出最终的图像, 这一阶段也是在GPU上进行的.

光栅化的任务主要是决定每个渲染图元中的那些像素应该被绘制在屏幕上  
这需要对上个阶段得到的*逐顶点数据(纹理坐标,顶点颜色等)*进行插值, 然后进行逐像素处理.

光栅化也可以分成更小的流水线

> 上述所有流水线均为概念流水线, 是依据渲染流程进行基本功能划分而提出的, 下面介绍GPU的流水线, 则是硬件真正用于实现上述概念的实际流水线.

## CPU和GPU之间的通信

渲染流水线起始于CPU,也就是应用阶段, 大致分为下面3个阶段.
1. 吧数据加载到显存中
2. 设置渲染状态
3. 调用`Draw Call`(后续讨论Draw Call是什么)

### 吧数据加载到显存中

硬盘, 内存, 显存, 访问速度越来越快  

而且, 绝大多数显卡对于内存没有访问权限

理论上讲, 数据加载到显存后,就可以从内存中卸载他们了, 但是CPU可能希望访问这些数据, 所以有时候并不会卸载.

### 设置渲染状态

指使用的顶点着色器, 片元着色器, 光源,材质等数据

### 调用Draw Call

所有数据准备完毕后, CPU就可以通知GPU来进行渲染了.

这就是一个Draw Call  
由CPU发起,GPU执行, 这个指定传递一个图元列表, 这是CPU处理后的数据集合

### 概述

应用阶段(CPU), 开发者拥有很大的主导权, 但到了几何阶段(GPU),光栅化阶段(GPU), 我们能做的事情有限.

## GPU流水线

* 顶点数据
* 几何阶段
  * 顶点着色器(必须, 可编程)
  * 曲面细分着色器(非必须, 可编程)
  * 几何着色器(非必须, 可编程)
  * 裁剪(可配置)
  * 屏幕映射(无权限)
* 光栅化阶段
  * 三角形设置(无权限)
  * 三角形遍历(无权限)
  * 片元着色器(非必须, 可编程)
  * 逐片元操作(可配置)
* 屏幕图像

### 顶点着色器

流水线的第一个阶段.  

每个输入的顶点都会调用一次顶点着色器  
顶点着色器并不创建或者销毁任何顶点, 也无法得知顶点与顶点之间的关系  
但正是因为这样的相互独立性, GPU可以利用本身的特性并行处理每个顶点

这意味着, 这一阶段的处理将会很快.

顶点着色器的主要工作内容有: 坐标变换,逐顶点光照,构建自定义数据.

利用变换坐标功能, 我们可以动态改变顶点坐标, 以达成水面,布料等功能.  
当然, 不要忘了最基础的, **一定要**吧顶点坐标转换到裁剪空间.

```HLSL
o.pos = mul(UNITY_MVP, v.position);
```

接下来就是硬件做透视除法, 得到归一化设备坐标(NDC, Normalized Device Coordinates)

> 后续的曲面细分着色器,几何着色器,自行了解

### 裁剪

裁剪, 区别于之前应用阶段的剔除, 这里是针对顶点和三角面的  
只有在视野内的顶点才会保留, 视野外的顶点被丢弃, 如果一个三角面一半在内一半在外, 则丢弃外部的, 重写生成符合视野的新三角面.

> 此过程无法编程, 但可以进行一些配置.

### 屏幕映射(Screen Mapping)

讲裁剪空间下的xy坐标转换到屏幕坐标系(Screen Coordinates)  
也是依据屏幕大小缩放.

其中z值不会处理, 将和xy共同构成窗口坐标系(Window Coordinates), 这些值会被一起传递到光栅化阶段.

> OpenGL定义左下为(0,0), DirectX定义左上为(0,0)  
> 这可能是由于微软窗口就是这样定义的, 也可能是源于人类阅读方式, 从上到下, 从左到右.

### 三角形设置

现在开始进入光栅化阶段

光栅化阶段的目标是计算图元覆盖了哪些像素, 以及计算这些像素的值.

几何极端进行的都是顶点操作, 现在我们依据顶点形成三角形, 这就是三角形设置

### 三角形遍历(Triangle Traversal)

检查每个像素是否被一个三角形覆盖, 如果是,则生成一个片元(fragment).  
也被称为扫描变换(Scan Conversion)

> 首先依据两个顶点链接成线, 对线中的片元执行依据顶点的插值计算, 之后对三角形的点进行生成和插值计算

> 片元并非真正的像素, 而是包含了很多状态的数据集合, 包括用于计算像素最终值的颜色, 屏幕坐标, 深度, 其他从几何阶段定义的信息(顶点,法线,纹理等.)

### 片元着色器

在DirectX中也被称为像素着色器, 但实际他们还不是像素.

片元着色器接受上一阶段插值生成的这些片元数据, 进行一些可编程操作.

最重要的就是纹理采样, 使用插值后的数据, 采样对应的纹理颜色.

但注意, 每个片元并不能讲自己的信息共享给邻居.

### 逐片元操作

DirectX中称为 输出合并阶段(Output-Merger) Merger一词便是重点.

这一阶段需要做

1. 决定每个片元的可见性, 涉及到深度测试, 模板测试等.
2. 如果有片元通过测试, 讲其颜色与颜色缓冲区中的颜色进行合并, 或者说混合.

这一阶段虽然不能编程, 但是高度可配置的.

> 没有过通过测试的片元, 直接被丢弃, 之前的工作的白费了.  
> 所以有些时候可以看到提前的深度测试, 称为`Early-Z`.  
> 但这有带来其他问题, 提前筛选掉的片元不在参与其他测试, 导致效果不符合预期. 但是现代GPU一般有一个判断, 依据操作是否可能和提前测试冲突来决定是否起开提前测试. 这就是为什么透明度测试会导致性能下降的原因.

最终得到的像素点被存储于后置缓冲区, 一旦后置缓冲区被填满, GPU就将其交换到前置缓冲区, 也就是我们看到的屏幕上的图像. 这保证我们看到的图像总是连续的.

## 总结

每个资料给出的流水线流程和名称各不相同, 这主要是由于编程接口(OpenGL,DirectX)的实现不尽相同, 还有GPU底层的优化导致的.

# Unity Shader基础

Unity提供了一个方便的框架来处理渲染设置和着色器代码.

## 概述

Material和UnityShader, 他们通常是一起出现的, 材质持有UnityShader, 物体持有材质.

UnityShader定义渲染需要的代码(顶点着色器,片元着色器),属性(纹理,反射),指令(渲染设置,标签设置).  
而材质允许我们调节这些属性. 并将其赋值给相应的模型.

> 可以注意到, 上面使用的都是UnityShader, 这是由于UnityShader与之前提及的渲染管线的Shader很大不同, 后面会提到.

## UnityShader的基础:ShaderLab

这是Unity提供给开发者的高层级的渲染抽象层, 使开发者轻松控制渲染.

> Unity会讲ShaderLab编译为真正的Shader代码, 开发者无需关心.  
> 真想关心可以点击`Compile and show code` 查看Unity为不同编程接口生成的底层汇编指令.

## UnityShader的结构

SubShader, 最少有一个, 可以包含多个.  
只会运行其中的一个, 写多个一般是为了适配不同的平台和机型, 以便控制性能和复杂度.

```HLSL
SubShader{
	[Tags]
	[RenderSetup]
	Pass
	{

	}
}
```
Tags是标签, RenderSetup是状态设置, Pass则定义了一个完成的渲染流程, 如果Pass过多, 则会渲染多次, 也自然会消耗更多性能.  
Pass中也可以使用标签和状态设置, 但有些内容是SubShader特有的, 且在SubShader中的设置, 将应用于所有的Pass

```HLSL
Pass
{
	[Name]
	[Tags]
	[RenderSetup]
}
```

拥有Name, 可以用ShaderLab的UsePass命令直接使用其他UnityShader中的Pass  
提高代码的复用性  

Fallback, 可以跟在SubShader语句后面, 用于表示, 如果所有SubShader都不能在此机器上运行, 则使用这个Shader吧.  
基本就是用来表示, 最低级的UnityShader是谁 

当然, 你也可以关闭Fallback, 这表明, 如果不能执行,就不要执行了.

## UnityShader的形式

### 表面着色器

Unity最后还是将其转化为了顶点和片元Shader, 只是帮我们省了一些操作

### 顶点, 片元着色器

### 固定函数着色器

不支持可编程渲染管线, 就可以使用这个.

> 实际已经不存在了, 最终都被编译为了顶点,片元着色器.

> CG和DX9风格的HLSL几乎是同一种语言, 所以我们常说 `CG/HLSL`

# 学习Shader所需的数学基础

## 笛卡尔坐标系

笛卡尔坐标系就是直角坐标系和斜角坐标系的统称

OpenGL的屏幕映射笛卡尔坐标系, 原点在左下  
DiectX的屏幕映射笛卡尔坐标系, 原点在左上

### 左手坐标系和右手坐标系

坐标轴的方向并不是固定的

但在二维的坐标系中, 我们总可以通过旋转,翻转等手段来使坐标系变为相同.  
但三维的坐标系则不能如此

对于一个XY方向相同,仅Z轴颠倒的坐标系, 无论如何旋转,翻转,最多只有两个轴能方向相同.

> 旋转的正方向: 伸出拇指指向要旋转的轴的正方向, 剩下四根手指弯曲的方向就是旋转正方向.

> 左收坐标系可以通过翻转任何一个轴来变为右手坐标系, 再反转就可以转会左手坐标系  
> 一般是吧z轴取反

**对于不同坐标系,达到同样的视觉效果需要做的数学运算不相同**  
反而言之,使用相同的数学运算,会达成不一样的视觉效果

对于模型空间和世界空间, Unity使用左手坐标系   
但对于观察空间(以摄像机为原点的空间), Unity使用右手坐标系

### 习题

1. 右手坐标系
2. 1,0,0 和 1,0,0
3. 0,0,-10, 0,0,10

> 批改:全部正确

## 点和矢量

### 矢量和标量的乘除法

也就是标量和矢量的每个位相乘, 或相除  
对于相除, 只能是矢量除以标量, 且标量不能为0

### 矢量的加减

实际上就是矢量的每个对应分量进行加减即可.

从几何意义上来看, a+b等于他们相对于原点的位移, b-a等于b相对于a的位移

### 矢量的模

是一个标量, 可以理解为矢量在空间中的长度

对每个分量进行平方后相加, 然后开方.

> 对于二维矢量, 这其实就是勾股定理

### 矢量的点积

矢量之间的乘法, 点积也被称为内积

> UnityShader中, 可使用`dot(a,b)`来计算点积

点积来自于这种运算符号 `a·b`

有两种形式, 先看第一种  
将两个三维的矢量对应的分量相乘再取和. 结果是一个标量

`(1,2,3)·(0.5,4,2.5) = 0.5 + 8 + 7.5 = 16`

其几何意义为投影, 这几乎存在于图形学的各个方面

有一光源垂直于A方向(视A为地面), B在A方向上的投影就是 B在地面的影子.

注意, 投影可能为负数, 这取决于B相对于A的方向, 也就是两者的夹角  
夹角小于90°则为正数, 等于则为0, 大于则为负数

拥有结合性质, 可与标量相乘, 矢量加减法结合.   
矢量和自身点积, 得到该矢量模的平方.

> 这可以快速比较两个矢量的大小, 也不必开平方, 因为开平方有性能消耗

第二种形式如下

a·b = |a||b|cosθ

cosθ = 直角边/斜边

当|b|等于1时, 投影恰好是直角边

两个矢量的点积,可与表示为两个矢量的模相乘, 再乘以他们之间夹角的余弦值.

> 夹角小于90°则为正数, 等于则为0, 大于则为负数. 这也是余弦的定义

还可以使用`arcos(a·b) = θ`得到夹角(0°~180°)

### 向量的叉积

### 矢量的差积

矢量之间的惩罚, 差积也被称为外积

# 完毕

**感谢您的观看!**  
本文来自 [ML-Blog][ML-Blog_Link]

<!-- 图片 -->

<!-- 链接 -->

<!-- 水印 -->
[ML-Blog_Link]:https://userminghaoli.github.io/ "我的博客"
